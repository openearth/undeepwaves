{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "deep-wave-model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLIYyvTgCdUQ"
      },
      "source": [
        "# builtins\n",
        "import locale\n",
        "import math\n",
        "import glob\n",
        "import pathlib\n",
        "import functools\n",
        "import logging\n",
        "\n",
        "# numerical stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, Input, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF8xF7KjFyrQ",
        "outputId": "6ac5c236-b7f6-45c7-c2c6-bbfe8a94c14c"
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=5rMAZsB7pnyM4sagC8f04CnLKY8YWw&prompt=consent&access_type=offline&code_challenge=lWKTknde_yXZueQ1vkJ6X5tyqq7aCd34PpdP2guQFgk&code_challenge_method=S256\n",
            "\n",
            "Enter verification code: 4/1AX4XfWiMdSIfrLRPnpdRmoG0g811kqUEm4dePjEgSy-LOdTd3wZnmbWceDE\n",
            "\n",
            "You are now logged in as [f.baart@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUdhoHlwCdUj"
      },
      "source": [
        "data_path = 'gs://bathy_sample/processed/20211013/combined_data'\n",
        "all_checkpoints_path = 'gs://bathy_sample/dnn/checkpoints'\n",
        "all_checkpoints_path = 'checkpoints'\n",
        "model_name = 'guus-2d-mlp-cnn-v0.1'\n",
        "learning_rate = 1e-4\n",
        "n_epochs = 20\n",
        "batch_size = 8\n",
        "checkpoints_path = all_checkpoints_path + '/' + model_name\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpjHE6VXCdUk"
      },
      "source": [
        "def tf_parse(eg):\n",
        "    \"\"\"parse an example (or batch of examples, not quite sure...)\"\"\"\n",
        "\n",
        "    # here we re-specify our format\n",
        "    # you can also infer the format from the data using tf.train.Example.FromString\n",
        "    # but that did not work\n",
        "    example = tf.io.parse_example(\n",
        "        eg[tf.newaxis],\n",
        "        {\n",
        "            \"height\": tf.io.FixedLenFeature([], tf.int64),\n",
        "            \"width\": tf.io.FixedLenFeature([], tf.int64),\n",
        "            \"depth\": tf.io.FixedLenFeature([], tf.int64),\n",
        "            \"bathy\": tf.io.FixedLenFeature([], tf.string),\n",
        "            \"hs\": tf.io.FixedLenFeature([], tf.string),\n",
        "            \"eta\": tf.io.FixedLenFeature([], tf.float32),\n",
        "            \"zeta\": tf.io.FixedLenFeature([], tf.float32),\n",
        "            \"theta\": tf.io.FixedLenFeature([], tf.float32),\n",
        "        },\n",
        "    )\n",
        "    bathy = tf.io.parse_tensor(example[\"bathy\"][0], out_type=\"float32\")\n",
        "    hs = tf.io.parse_tensor(example[\"hs\"][0], out_type=\"float32\")\n",
        "    eta = example[\"eta\"]\n",
        "    zeta = example[\"zeta\"]\n",
        "    theta = example[\"theta\"]\n",
        "    attr = tf.stack([eta, zeta, theta], axis=1)\n",
        "    attr = tf.reshape(attr, shape=[-1])\n",
        "    return (bathy, attr), hs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYgkDjQeCdUp"
      },
      "source": [
        "def get_files(data_path):\n",
        "    files = tf.io.gfile.glob(data_path + \"/\" + \"*.tfrecords\")\n",
        "    return files\n",
        "\n",
        "def get_dataset(files):\n",
        "    \"\"\"return a tfrecord dataset with all tfrecord files\"\"\"\n",
        "    dataset =  tf.data.TFRecordDataset(files)\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR02VYyxCdUr"
      },
      "source": [
        "def create_mlp(dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=dim, activation=\"relu\"))\n",
        "    model.add(Dense(1024, activation=\"relu\"))\n",
        "    model.add(Dense(256 * 256, activation=\"relu\"))\n",
        "    model.build((None, 256 * 256))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_cnn(width, height, depth):\n",
        "    input_shape = (height, width, depth)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    ax = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Branch 1\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(ax)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    bx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Branch 2\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(bx)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    cx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Branch 3\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(cx)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2DTranspose(32, (3, 3), padding=\"same\")(x)\n",
        "\n",
        "    # Branch 2\n",
        "    x = Concatenate()([x, cx])\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2DTranspose(32, (3, 3), padding=\"same\")(x)\n",
        "\n",
        "    # Branch 1\n",
        "    x = Concatenate()([x, bx])\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2DTranspose(32, (3, 3), padding=\"same\")(x)\n",
        "\n",
        "    # Main Branch\n",
        "    x = Concatenate()([x, ax])\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def full_model(cnn_model, mlp_model):\n",
        "\n",
        "    x = cnn_model.output\n",
        "    cx = mlp_model.output\n",
        "\n",
        "    conv_shape = K.int_shape(x)\n",
        "\n",
        "    cx = Reshape((conv_shape[1], conv_shape[2], int(conv_shape[3] / 4)))(cx)\n",
        "\n",
        "    x = Concatenate()([x, cx])\n",
        "\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2DTranspose(1, (3, 3), padding=\"same\", activation=\"linear\")(x)\n",
        "\n",
        "    model = Model(inputs=[cnn_model.input, mlp_model.input], outputs=x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKXtM9o7CdUt",
        "outputId": "59ae4e69-7a49-4711-fc3d-bfb5c7b23b5d"
      },
      "source": [
        "files = get_files(data_path)\n",
        "train_files, test_files = train_test_split(files)\n",
        "train_dataset = get_dataset(train_files)\n",
        "test_dataset = get_dataset(test_files)\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "len(train_files), len(test_files)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35TQPKpZCdUx"
      },
      "source": [
        "cnn_model = create_cnn(256, 256, 1)\n",
        "mlp_model = create_mlp(3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJgaWF4QCdUz"
      },
      "source": [
        "model = full_model(cnn_model, mlp_model)\n",
        "opt = Adam(learning_rate=learning_rate, decay=learning_rate / n_epochs)\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=['mse'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHrVIhN4CdUz",
        "outputId": "80b9395e-2cf0-4f5b-b101-d1310c4dc503"
      },
      "source": [
        "logging.info(\"training model...\")\n",
        "# TODO properly compute steps for progress bar (low priority)\n",
        "steps_per_epoch = len(train_files) * 10 // batch_size\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoints_path, \n",
        "        save_weights_only=True,\n",
        "        monitor='val_mse',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "model.fit(x=train_dataset, validation_data=test_dataset, epochs=n_epochs, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "95/95 [==============================] - 52s 511ms/step - loss: 44.3176 - mse: 44.3176 - val_loss: 31.1961 - val_mse: 31.1961\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 47s 498ms/step - loss: 38.8607 - mse: 38.8607 - val_loss: 17.2756 - val_mse: 17.2756\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 47s 492ms/step - loss: 32.5795 - mse: 32.5795 - val_loss: 11.7284 - val_mse: 11.7284\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 47s 489ms/step - loss: 23.3622 - mse: 23.3622 - val_loss: 8.3155 - val_mse: 8.3155\n"
          ]
        }
      ]
    }
  ]
}